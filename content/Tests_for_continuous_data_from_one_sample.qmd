---
title: One sample tests for continuous data
subtitle: The one where we fully introduce normality
bibliography: references.bib
---

In this chapter will build on our introduction to significance testing
by considering tests for continuous data collected on one trait from a
single population. This will also allow/require us to more fully define
*normal* distributions, which we have already started to discuss.

## Example

Let's return to our iris data and focus on sepal lengths of *I.
viriginica*.

```{r}
library(ggplot2)
ggplot(iris[iris$Species == "virginica",],
              aes(x=Sepal.Length)) +
  geom_histogram( fill="blue", color="black") +
  labs(title=expression(paste("Sepal lengths of ",italic("I. virginica"))),
       x= "Sepal length (cm)",
       y= "Frequency")
```

What if we wanted to test if the height was equal to a certain value
like 7 cm?

**We can't, and it's not**.

Height is a random variable. It differs among individuals (see above),
so it isn't equal to any specific value. This may seem obvious, but it's
an important step in understanding hypothesis testing. Many students
also struggle with this, but most are with the fact we learned about
hypothesis testing focusing on proportions (remember the last chapter?).
When we focused on binomial data, it was obvious a single draw could not
be 2 things - it was a success or failure, and we focused on the
relative occurrence of those.

Similarly, for continuous numeric data (remember: data that can on any
value in a given range), we need to focus on describing the distribution
of the data. If we do that, we might want (and be able to test) if, for
example, the *mean* height of *I. virginica* is equal to 7 cm. In fact,
we typically focus on the *mean* of the distribution (one of measures of
central tendency)

To do this, we need to do what we did with binomial data: develop a null
hypotheses, use it to construct a null distribution, and compare our
data to it see how unusual it is (and get a p-value).

<details>

<summary>What is our null hypothesis for this example?</summary>

For this example, we are focused on a two-tailed test (we are asking if
the mean is equal to a certain value), so we have

$$
\begin{split}
H_O: \mu_{height} = 7 \ cm \\ 
H_A: \mu_{height} \neq 7 \ cm 
\end{split}
$$

</details>

Now that we have a null hypothesis, we need to test it. We can do this
by simulation. Let's make a distribution where the
$\mu_{height} =7 \  cm$, then draw samples from it and see how rare it
is to get what we actually observed in the data...which was

```{r}
mean(iris[iris$Species == "virginica","Sepal.Length"])
```

Seems easy enough, but what distribution do we draw from? For our
binomial data we knew exactly what to parameterize - that's because the
entire distribution is described by the parameter *p* (go back to the
last chapter and note we can find the spread using this one variable as
well!).

If you remember the central limit theorem, you might realize the
distribution of the data does not matter in some ways. No matter what it
looks like, the means of the data will tend towards normality. However,
we still need to describe it to simulate our draws.

It turns out the shape of the data itself appears fairly normal. So far
we've said normal distributions

-   are roughly symmetric, with tails on either side. Values near the
    middle of the range are more common, with the chance of getting
    smaller or larger values declining at an increasing rate

95% of the sample is within \\\~2 standard deviations of the mean (and
for our mean of means, 95% of the data is within 2 standard errors)

Look at a density function fit to the data:

```{r}
ggplot(iris[iris$Species == "virginica",],
              aes(x=Sepal.Length)) +
  geom_histogram(aes(y = ..density..),fill="blue", color="black") +
  geom_density()+
  labs(title=expression(paste("Sepal lengths of ",italic("I. virginica"))),
       x= "Sepal length (cm)",
       y= "Density")
```

It does appear to be fairly symmetric and peaked in the middle. It turns
out normal distributions (finally defined below!) are very common in
nature.

Just like the binomial data, a normal distribution can be described
using a formula. The formula has 2 parameters that define the shape of
the distribution. $\mu$ defines the center of the distribution, and
$\sigma^2$ describes its spread. The formula for the probabilty density
function is

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}
e^{\frac{-(x-\mu)^2}{2\sigma^2}} 
$$

This looks complicated, but remember: this is just an equation for
describing the likelihood of outcomes in a probability space! The first
part $\sqrt{2\pi\sigma^2}$ arises from trying to work with a curve. To
understand the rest, lets take the ln of both sides

$$
\begin{split}
\ln(f(x)) = \ln(\frac{1}{\sqrt{2\pi\sigma^2}}) - \frac{1}{2\sigma^2}*(x-\mu)^2 \\
\ln(f(x)) = -\ln(\sqrt{2\pi\sigma^2}) - \frac{1}{2\sigma^2}*(x-\mu)^2
\end{split}
$$

This may not look like it helps much, but we now have the formula for a
straight line, $y=mx+b$, where

$$
\begin{split}
y= \ln(f(x)) \\
b = - \frac{1}{2\sigma^2}\\
m = -\ln(\sqrt{2\pi\sigma^2})\\
x =  (x-\mu)^2
\end{split}
$$

In other words, our independent variable is the squared distance from
the mean (so all positive)! Note both the y-intercept (the amplitude)
and slope (shape) depends on how spread out the data is ($\sigma^2$).
Note in general when ln(y) decreases linearly with x, y decreases at a
constant proportional rate with x. So we can say a normal random variate
is any random variable in which the probability of an observation
declines in proportion to its squared deviation from the mean (µ).

Let's fit a normal distribution to our data:

```{r}
colors <- c("PDF from data" = "black", "normal curve" = "red")
ggplot(iris[iris$Species == "virginica",],
              aes(x=Sepal.Length)) +
  geom_histogram(aes(y = ..density..),fill="blue", color="black") +
  geom_density(aes(color="PDF from data"))+
  labs(title="Weight of Westchester parrots",
       x= "Weight (g)",
       y= "Density",
       color="Source" ) +
stat_function(fun = dnorm, args = list(mean = mean(iris[iris$Species == "virginica","Sepal.Length"]), sd = sd(iris[iris$Species == "virginica","Sepal.Length"])), aes(color="normal curve"))+
      scale_color_manual(values = colors)

```

Note it fits fairly well, so we'll use it for our sampling experiment.
