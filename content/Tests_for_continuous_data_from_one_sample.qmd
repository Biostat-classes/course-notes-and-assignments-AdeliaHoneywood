---
title: One sample tests for continuous data
subtitle: The one where we fully introduce normality
bibliography: references.bib
---

In this chapter will build on our introduction to significance testing
by considering tests for continuous data collected on one trait from a
single population. This will also allow/require us to more fully define
*normal* distributions, which we have already started to discuss.

## Example

Let's return to our iris data and focus on sepal lengths of *I.
viriginica*.

```{r}
set.seed(42)
library(ggplot2)
ggplot(iris[iris$Species == "virginica",],
              aes(x=Sepal.Length)) +
  geom_histogram( fill="blue", color="black") +
  labs(title=expression(paste("Sepal lengths of ",italic("I. virginica"))),
       x= "Sepal length (cm)",
       y= "Frequency")
```

What if we wanted to test if the height was equal to a certain value
like 7 cm?

**We can't, and it's not**.

Height is a random variable. It differs among individuals (see above),
so it isn't equal to any specific value. This may seem obvious, but it's
an important step in understanding hypothesis testing. Many students
also struggle with this, but most are with the fact we learned about
hypothesis testing focusing on proportions (remember the last chapter?).
When we focused on binomial data, it was obvious a single draw could not
be 2 things - it was a success or failure, and we focused on the
relative occurrence of those.

Similarly, for continuous numeric data (remember: data that can on any
value in a given range), we need to focus on describing the distribution
of the data. If we do that, we might want (and be able to test) if, for
example, the *mean* height of *I. virginica* is equal to 7 cm. In fact,
we typically focus on the *mean* of the distribution (one of measures of
central tendency)

To do this, we need to do what we did with binomial data: develop a null
hypotheses, use it to construct a null distribution, and compare our
data to it see how unusual it is (and get a p-value).

<details>

<summary>What is our null hypothesis for this example?</summary>

For this example, we are focused on a two-tailed test (we are asking if
the mean is equal to a certain value), so we have

$$
\begin{split}
H_O: \mu_{height} = 7 \ cm \\ 
H_A: \mu_{height} \neq 7 \ cm 
\end{split}
$$

</details>

Now that we have a null hypothesis, we need to test it. We can do this
by simulation. Let's make a distribution where the
$\mu_{height} =7 \  cm$, then draw samples from it and see how rare it
is to get what we actually observed in the data...which was

```{r}
mean(iris[iris$Species == "virginica","Sepal.Length"])
```

Seems easy enough, but what distribution do we draw from? For our
binomial data we knew exactly what to parameterize - that's because the
entire distribution is described by the parameter *p* (go back to the
last chapter and note we can find the spread using this one variable as
well!).

If you remember the central limit theorem, you might realize the
distribution of the data does not matter in some ways. No matter what it
looks like, the means of the data will tend towards normality. However,
we still need to describe it to simulate our draws.

It turns out the shape of the data itself appears fairly normal. So far
we've said normal distributions

-   are roughly symmetric, with tails on either side. Values near the
    middle of the range are more common, with the chance of getting
    smaller or larger values declining at an increasing rate

95% of the sample is within \\\~2 standard deviations of the mean (and
for our mean of means, 95% of the data is within 2 standard errors)

Look at a density function fit to the data:

```{r}
ggplot(iris[iris$Species == "virginica",],
              aes(x=Sepal.Length)) +
  geom_histogram(aes(y = ..density..),fill="blue", color="black") +
  geom_density()+
  labs(title=expression(paste("Sepal lengths of ",italic("I. virginica"))),
       x= "Sepal length (cm)",
       y= "Density")
```

It does appear to be fairly symmetric and peaked in the middle. It turns
out normal distributions (finally defined below!) are very common in
nature.

Just like the binomial data, a normal distribution can be described
using a formula. The formula has 2 parameters that define the shape of
the distribution. $\mu$ defines the center of the distribution, and
$\sigma^2$ describes its spread. The formula for the probabilty density
function is

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}
e^{\frac{-(x-\mu)^2}{2\sigma^2}} 
$$

This looks complicated, but remember: this is just an equation for
describing the likelihood of outcomes in a probability space! The first
part $\sqrt{2\pi\sigma^2}$ arises from trying to work with a curve. To
understand the rest, lets take the ln of both sides

$$
\begin{split}
\ln(f(x)) = \ln(\frac{1}{\sqrt{2\pi\sigma^2}}) - \frac{1}{2\sigma^2}*(x-\mu)^2 \\
\ln(f(x)) = -\ln(\sqrt{2\pi\sigma^2}) - \frac{1}{2\sigma^2}*(x-\mu)^2
\end{split}
$$

This may not look like it helps much, but we now have the formula for a
straight line, $y=mx+b$, where

$$
\begin{split}
y= \ln(f(x)) \\
b = - \frac{1}{2\sigma^2}\\
m = -\ln(\sqrt{2\pi\sigma^2})\\
x =  (x-\mu)^2
\end{split}
$$

In other words, our independent variable is the squared distance from
the mean (so all positive)! Note both the y-intercept (the amplitude)
and slope (shape) depends on how spread out the data is ($\sigma^2$).
Note in general when ln(y) decreases linearly with x, y decreases at a
constant proportional rate with x. So we can say a normal random variate
is any random variable in which the probability of an observation
declines in proportion to its squared deviation from the mean (µ).

Let's fit a normal distribution to our data:

```{r}
colors <- c("PDF from data" = "black", "normal curve" = "red")
ggplot(iris[iris$Species == "virginica",],
              aes(x=Sepal.Length)) +
  geom_histogram(aes(y = ..density..),fill="blue", color="black") +
  geom_density(aes(color="PDF from data"))+
  labs(title="Weight of Westchester parrots",
       x= "Weight (g)",
       y= "Density",
       color="Source" ) +
stat_function(fun = dnorm, args = list(mean = mean(iris[iris$Species == "virginica","Sepal.Length"]), sd = sd(iris[iris$Species == "virginica","Sepal.Length"])), aes(color="normal curve"))+
      scale_color_manual(values = colors)

```

Note it fits fairly well, so we'll use it for our sampling experiment.
To do so, we'll take 50 draws (since we had a sample size of 50) from a
normal distribution, find means for each draw, then consider their
distribution.

```{r}
number_of_draws <- 50
number_of_simulations <- 1000

sampling_experiment<- data.frame("observed_mean" = rep(NA, number_of_simulations))
for(i in 1:number_of_simulations){
sampling_experiment$observed_mean[i] = mean(rnorm(50, 7, sd = sd(iris[iris$Species == "virginica","Sepal.Length"])))
}

```

Let's check out the first few outcomes

```{r}
head(sampling_experiment)
```

and plot them

```{r}
ggplot(sampling_experiment,
              aes(x=observed_mean)) +
  geom_histogram(color="black") +
  labs(title="Observed means from 1000 random draws",
       x= "Mean",
       y= "Frequency")
```

Now let's see how that compares to what we actually saw.

```{r}
sampling_experiment$compare =   ifelse(abs(sampling_experiment$observed_mean-7) >= abs(mean(iris[iris$Species == "virginica","Sepal.Length"])-7), 'as or more extreme', 'not as or more extreme')

sampling_experiment$compare <- factor(sampling_experiment$compare)
levels(sampling_experiment$compare) <- c(levels(sampling_experiment$compare), "as or more extreme")

ggplot(sampling_experiment,
              aes(x=observed_mean, fill=compare)) +
  geom_histogram(color="black") +
  labs(title="Observed means from 1000 random draws",
       x= "Mean",
       y= "Frequency", 
       fill = "Sampled mean is ...") +
    scale_fill_discrete(drop = FALSE)

```

So in our example simulation, **no** observed means were as far from the
value from the null hypothesis as our sample mean was. This would leave
to a p-value of 0 - unusual in some regards, but possible here.

## Z-test: a distribution based approach

Just like we saw for binomial data, this approach is always doable but
mainly due to computers. Otherwise we would need to repeat the sampling
experiment for any change in sample size, mean, or standard deviation.
Instead, we can use the formula above to *approximate* the distribution
of sampling means. This is an *approximate* solution because our means
approach a normal distribution as sample size increases - so for
non-infinity sample sizes, they may not be perfectly normal! We call
this the z-test, and it can be carried out using the z.test function in
the BDSA package.

```{r}
library(BSDA)
z.test(iris[iris$Species == "virginica","Sepal.Length"], mu = 7, 
             sigma.x= sd(iris[iris$Species == "virginica","Sepal.Length"]))
```

Using this approach we get a p-value of .000005 - not 0, but very close!

### A little history

Although software now provides us exact (approximate) p-values,
historically this was far more difficult. For this reason, people took
advantage of a transformation so they could use a standardized table of
p-values. For *any* normally-distributed population, we can get a z
score using

$$
z=\frac{x - \mu}{\sigma}
$$

This transforms a given data point into a z-score on the z, or standard
normal, distribution. This distribution is centered at 0 (think about
it - if you subtract the mean from all data points...) and has a
standard deviation of 1 (because you divided by the standard
deviation!). This also means \~68% of the data points lie between -1 and
1, while \~95% lie between -2 and 2 (since the standard deviation is
1!).

This method allowed any data to be considered using a standard table
such as this one:

[![Example of z-table. Jsmura, Creative Commons Attribution-Share Alike
4.0 International
licence](/images/Tabla_z.png){fig-align="center"}](https://commons.wikimedia.org/wiki/File:Tabla_z.png)

In general would add the percentage (P above) of data points as or more
extreme than what you observed to get a p-value.

For our example, we got a z score of -4.8515

## Does the distribution of the data matter?

Remember we are focusing on the distribution of the means. Given that
and the central limit theorem, does the distribution of the data matter?
Yes, but only in regards to the relationship between sample size and
normality of the sample means. If the underlying data is normal, then
the sampled means are distributed normally for almost *any* sample size.
Note

```{r}

```

For other distributions, large sample sizes are required to approximate
normality. For example,

```{r}

```

### QQnorm

## What if we don't know the variance?

```{r}
t.test(iris[iris$Species == "virginica","Sepal.Length"], mu = 7, 
             sigma.x= sd(iris[iris$Species == "virginica","Sepal.Length"]))

```

## What if we don't trust the normal approximation?
