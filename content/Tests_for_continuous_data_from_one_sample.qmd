---
title: One sample tests for continuous data
subtitle: The one where we fully introduce normality
bibliography: references.bib
---

In this chapter will build on our introduction to significance testing
by considering tests for continuous data collected on one trait from a
single population. This will also allow/require us to more fully define
*normal* distributions, which we have already started to discuss.

## Example

Let's return to our iris data and focus on sepal lengths of *I.
viriginica*.

```{r}
set.seed(42)
library(ggplot2)
ggplot(iris[iris$Species == "virginica",],
              aes(x=Sepal.Length)) +
  geom_histogram( fill="blue", color="black") +
  labs(title=expression(paste("Sepal lengths of ",italic("I. virginica"))),
       x= "Sepal length (cm)",
       y= "Frequency")
```

What if we wanted to test if the height was equal to a certain value
like 7 cm?

**We can't, and it's not**.

Height is a random variable. It differs among individuals (see above),
so it isn't equal to any specific value. This may seem obvious, but it's
an important step in understanding hypothesis testing. Many students
also struggle with this, but most are with the fact we learned about
hypothesis testing focusing on proportions (remember the last chapter?).
When we focused on binomial data, it was obvious a single draw could not
be 2 things - it was a success or failure, and we focused on the
relative occurrence of those.

Similarly, for continuous numeric data (remember: data that can on any
value in a given range), we need to focus on describing the distribution
of the data. If we do that, we might want (and be able to test) if, for
example, the *mean* height of *I. virginica* is equal to 7 cm. In fact,
we typically focus on the *mean* of the distribution (one of measures of
central tendency)

To do this, we need to do what we did with binomial data: develop a null
hypotheses, use it to construct a null distribution, and compare our
data to it see how unusual it is (and get a p-value).

<details>

<summary>What is our null hypothesis for this example?</summary>

For this example, we are focused on a two-tailed test (we are asking if
the mean is equal to a certain value), so we have

$$
\begin{split}
H_O: \mu_{height} = 7 \ cm \\ 
H_A: \mu_{height} \neq 7 \ cm 
\end{split}
$$

</details>

Now that we have a null hypothesis, we need to test it. We can do this
by simulation. Let's make a distribution where the
$\mu_{height} =7 \  cm$, then draw samples from it and see how rare it
is to get what we actually observed in the data...which was

```{r}
mean(iris[iris$Species == "virginica","Sepal.Length"])
```

Seems easy enough, but what distribution do we draw from? For our
binomial data we knew exactly what to parameterize - that's because the
entire distribution is described by the parameter *p* (go back to the
last chapter and note we can find the spread using this one variable as
well!).

If you remember the central limit theorem, you might realize the
distribution of the data does not matter in some ways. No matter what it
looks like, the means of the data will tend towards normality. However,
we still need to describe it to simulate our draws.

It turns out the shape of the data itself appears fairly normal. So far
we've said normal distributions

-   are roughly symmetric, with tails on either side. Values near the
    middle of the range are more common, with the chance of getting
    smaller or larger values declining at an increasing rate

95% of the sample is within \\\~2 standard deviations of the mean (and
for our mean of means, 95% of the data is within 2 standard errors)

Look at a density function fit to the data:

```{r}
ggplot(iris[iris$Species == "virginica",],
              aes(x=Sepal.Length)) +
  geom_histogram(aes(y = ..density..),fill="blue", color="black") +
  geom_density()+
  labs(title=expression(paste("Sepal lengths of ",italic("I. virginica"))),
       x= "Sepal length (cm)",
       y= "Density")
```

It does appear to be fairly symmetric and peaked in the middle. It turns
out normal distributions (finally defined below!) are very common in
nature.

Just like the binomial data, a normal distribution can be described
using a formula. The formula has 2 parameters that define the shape of
the distribution. $\mu$ defines the center of the distribution, and
$\sigma^2$ describes its spread. The formula for the probabilty density
function is

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}
e^{\frac{-(x-\mu)^2}{2\sigma^2}} 
$$

This looks complicated, but remember: this is just an equation for
describing the likelihood of outcomes in a probability space! The first
part $\sqrt{2\pi\sigma^2}$ arises from trying to work with a curve. To
understand the rest, lets take the ln of both sides

$$
\begin{split}
\ln(f(x)) = \ln(\frac{1}{\sqrt{2\pi\sigma^2}}) - \frac{1}{2\sigma^2}*(x-\mu)^2 \\
\ln(f(x)) = -\ln(\sqrt{2\pi\sigma^2}) - \frac{1}{2\sigma^2}*(x-\mu)^2
\end{split}
$$

This may not look like it helps much, but we now have the formula for a
straight line, $y=mx+b$, where

$$
\begin{split}
y= \ln(f(x)) \\
b = - \frac{1}{2\sigma^2}\\
m = -\ln(\sqrt{2\pi\sigma^2})\\
x =  (x-\mu)^2
\end{split}
$$

In other words, our independent variable is the squared distance from
the mean (so all positive)! Note both the y-intercept (the amplitude)
and slope (shape) depends on how spread out the data is ($\sigma^2$).
Note in general when ln(y) decreases linearly with x, y decreases at a
constant proportional rate with x. So we can say a normal random variate
is any random variable in which the probability of an observation
declines in proportion to its squared deviation from the mean (µ).

Let's fit a normal distribution to our data:

```{r}
colors <- c("PDF from data" = "black", "normal curve" = "red")
ggplot(iris[iris$Species == "virginica",],
              aes(x=Sepal.Length)) +
  geom_histogram(aes(y = ..density..),fill="blue", color="black") +
  geom_density(aes(color="PDF from data"))+
    labs(title=expression(paste("Sepal lengths of ",italic("I. virginica"))),
       x= "Sepal length (cm)",
       y= "Density",
       color="Source" ) +
stat_function(fun = dnorm, args = list(mean = mean(iris[iris$Species == "virginica","Sepal.Length"]), sd = sd(iris[iris$Species == "virginica","Sepal.Length"])), aes(color="normal curve"))+
      scale_color_manual(values = colors)

```

Note it fits fairly well, so we'll use it for our sampling experiment.
To do so, we'll take 50 draws (since we had a sample size of 50) from a
normal distribution, find means for each draw, then consider their
distribution.

```{r}
number_of_draws <- 50
number_of_simulations <- 1000

sampling_experiment<- data.frame("observed_mean" = rep(NA, number_of_simulations))
for(i in 1:number_of_simulations){
sampling_experiment$observed_mean[i] = mean(rnorm(50, 7, sd = sd(iris[iris$Species == "virginica","Sepal.Length"])))
}

```

Let's check out the first few outcomes

```{r}
head(sampling_experiment)
```

and plot them

```{r}
ggplot(sampling_experiment,
              aes(x=observed_mean)) +
  geom_histogram(color="black") +
  labs(title="Observed means from 1000 random draws",
       x= "Mean",
       y= "Frequency")
```

Now let's see how that compares to what we actually saw.

```{r}
sampling_experiment$compare =   ifelse(abs(sampling_experiment$observed_mean-7) >= abs(mean(iris[iris$Species == "virginica","Sepal.Length"])-7), 'as or more extreme', 'not as or more extreme')

sampling_experiment$compare <- factor(sampling_experiment$compare)
levels(sampling_experiment$compare) <- c(levels(sampling_experiment$compare), "as or more extreme")

ggplot(sampling_experiment,
              aes(x=observed_mean, fill=compare)) +
  geom_histogram(color="black") +
  labs(title="Observed means from 1000 random draws",
       x= "Mean",
       y= "Frequency", 
       fill = "Sampled mean is ...") +
    scale_fill_discrete(drop = FALSE)

```

So in our example simulation, **no** observed means were as far from the
value from the null hypothesis as our sample mean was. This would leave
to a p-value of 0 - unusual in some regards, but possible here.

## Z-test: a distribution based approach

Just like we saw for binomial data, a simulation-based approach is
always doable but mainly due to computers. Otherwise we would need to
repeat the sampling experiment for any change in sample size, mean, or
standard deviation. Instead, we can also use the formula above to
*approximate* the distribution of sampling means. This is an
*approximate* solution because our means approach a normal distribution
as sample size increases - so for non-infinity sample sizes, they may
not be perfectly normal! We call this the z-test, and it can be carried
out using the z.test function in the BDSA package.

```{r}
library(BSDA)
z.test(iris[iris$Species == "virginica","Sepal.Length"], mu = 7, 
             sigma.x= sd(iris[iris$Species == "virginica","Sepal.Length"]))
```

Using this approach we get a p-value of .000005 - not 0, but very close!

### A little history

Although software now provides us exact (approximate) p-values,
historically this was far more difficult. For this reason, people took
advantage of a transformation so they could use a standardized table of
p-values. For *any* normally-distributed population, we can get a z
score (or statistic) using

$$
z=\frac{\bar{x} - \mu}{\sigma}
$$

This transforms a given data point into a z-score on the z, or standard
normal, distribution. This distribution is centered at 0 (think about
it - if you subtract the mean from all data points...) and has a
standard deviation of 1 (because you divided by the standard
deviation!). This also means \~68% of the data points lie between -1 and
1, while \~95% lie between -2 and 2 (since the standard deviation is
1!).

```{r, echo = F}
#| label: fig-z-colored
#| fig-cap: "~65% of the data lies with 1 standard deviation of the mean, ~95% lies within 2 standard deviations, and ~99% lies within 3 standard deviations of the mean
library(viridis)
colors <- setNames( viridis(5), c("0-1","1-2", "2-3", "3-4", "4+"))


#standard normal with 1-4 se highlighted ####
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) +
   stat_function(aes(fill="4+"), fun = dnorm, args = list(mean = 0, sd = 1), size = 3,
                geom = "area") +
  stat_function(aes(fill="3-4"),fun = dnorm, geom = "area", xlim =c(-4,4)) +
  stat_function(aes(fill="2-3"),fun = dnorm, geom = "area", xlim =c(-3,3)) +
  stat_function(aes(fill="1-2"),fun = dnorm, geom = "area", xlim =c(-2,2)) +
  stat_function(aes(fill="0-1"),fun = dnorm, geom = "area", xlim =c(-1,1)) +
  scale_x_continuous(breaks=seq(-5,5,1)) +
  labs(y="Probablity",
       x="Z score",
       fill="SE from mean") 
```

This method allowed any data that could be assumed to follow the note
assumptions to be considered using a standard table such as this one:

[![Example of z-table. Jsmura, Creative Commons Attribution-Share Alike
4.0 International
licence](/images/Tabla_z.png){fig-align="center"}](https://commons.wikimedia.org/wiki/File:Tabla_z.png)

In general would add the percentages (P above) of data points as or more
extreme than what you observed to get a p-value. Some tables only had
values \<0; for those you could find the value and multiple it by 2 for
two-tailed tests since the distribution is symmetric. For our example,
we got a z score of -4.8515. The table doesn't even go that low! In
general this allowed one table to used for all normal distributions (and
not different ones for all the possible combinations of means and
variances).

## Does the distribution of the data matter?

Remember we are focusing on the distribution of the means. Given that
and the central limit theorem, does the distribution of the data matter?
Yes, but only in regards to the relationship between sample size and
normality of the sample means. If the underlying data is normal, then
the sampled means are distributed normally for almost *any* sample size,
although sample size impacts the spread of the sample means.

```{r, echo = F}
#| label: fig-normal_draws
#| fig-cap:  Means drawn from a normal distribution are normal regardless of sample size
number_of_simulations <- 1000
sample_size=c("1","5","10", "20", "40", "80")

sampling_experiment <- setNames(data.frame(matrix(ncol = length(sample_size), nrow = number_of_simulations)), sample_size)
for(k in 1:length(sample_size)){
for(i in 1:number_of_simulations){
sampling_experiment[i,k] = mean(rnorm(n=as.numeric(sample_size[k])))
}
}

sampling_experiment_long <- melt(sampling_experiment, variable.name = "Sample_size", value.name = "mean")
sampling_experiment_long$Sample_size <- factor(sampling_experiment_long$Sample_size, levels =c("1","5","10", "20", "40", "80"))
levels(sampling_experiment_long$Sample_size) <- paste("Sample size of ", levels(sampling_experiment_long$Sample_size))

ggplot(sampling_experiment_long,aes(x=mean)) +
  geom_histogram(color="black") +
  labs(title=paste("Observed means from ", number_of_simulations, " random draws"),
       subtitle = "Normal distribution",  
       x= "Mean",
       y= "Frequency")+
    facet_wrap(~Sample_size, nrow = 2)
```

For other distributions, larger sample sizes are required to approximate
normality. For example, consider a highly-peaked (double-exponential)
distribution

```{r, echo=F}
sampling_experiment <- setNames(data.frame(matrix(ncol = length(sample_size), nrow = number_of_simulations)), sample_size)
library(VGAM)
for(k in 1:length(sample_size)){
for(i in 1:number_of_simulations){
sampling_experiment[i,k] = mean(rlaplace(n=as.numeric(sample_size[k])))
}
}

sampling_experiment_long <- melt(sampling_experiment, variable.name = "Sample_size", value.name = "mean")
sampling_experiment_long$Sample_size <- factor(sampling_experiment_long$Sample_size, levels =c("1","5","10", "20", "40", "80"))
levels(sampling_experiment_long$Sample_size) <- paste("Sample size of ", levels(sampling_experiment_long$Sample_size))

ggplot(sampling_experiment_long,aes(x=mean)) +
  geom_histogram(color="black") +
  labs(title=paste("Observed means from ", number_of_simulations, " random draws"),
       subtitle = "Double-exponential distribution",  
       x= "Mean",
       y= "Frequency")+
    facet_wrap(~Sample_size, nrow = 2)
```

or as skewed $\chi^2$ distribution (here with a df =4, to be explained
later!):

```{r, echo = F}

sampling_experiment <- setNames(data.frame(matrix(ncol = length(sample_size), nrow = number_of_simulations)), sample_size)
library(VGAM)
for(k in 1:length(sample_size)){
for(i in 1:number_of_simulations){
sampling_experiment[i,k] = mean(rchisq(n=as.numeric(sample_size[k]), df = 4))
}
}

sampling_experiment_long <- melt(sampling_experiment, variable.name = "Sample_size", value.name = "mean")
sampling_experiment_long$Sample_size <- factor(sampling_experiment_long$Sample_size, levels =c("1","5","10", "20", "40", "80"))
levels(sampling_experiment_long$Sample_size) <- paste("Sample size of ", levels(sampling_experiment_long$Sample_size))

ggplot(sampling_experiment_long,aes(x=mean)) +
  geom_histogram(color="black") +
  labs(title=paste("Observed means from ", number_of_simulations, " random draws"),
       subtitle = "Chi-squared distribution, df = 4",  
       x= "Mean",
       y= "Frequency")+
    facet_wrap(~Sample_size, nrow = 2)
```

Even for these very non-normal distributions, the means approach a
normal distribution at fairly low sample sizes. This is even true for
binomial data, especially when *p* is not very close to 0 or 1. Consider

```{r, echo=F}
sampling_experiment <- setNames(data.frame(matrix(ncol = length(sample_size), nrow = number_of_simulations)), sample_size)

for(k in 1:length(sample_size)){
for(i in 1:number_of_simulations){
sampling_experiment[i,k] = rbinom(n=1, size=as.numeric(sample_size[k]), prob=.7)/as.numeric(sample_size[k])
}
}

sampling_experiment_long <- melt(sampling_experiment, variable.name = "Sample_size", value.name = "mean")
sampling_experiment_long$Sample_size <- factor(sampling_experiment_long$Sample_size, levels =c("1","5","10", "20", "40", "80"))
levels(sampling_experiment_long$Sample_size) <- paste("Sample size of ", levels(sampling_experiment_long$Sample_size))

ggplot(sampling_experiment_long,aes(x=mean)) +
  geom_histogram(color="black") +
  labs(title=paste("Observed means from ", number_of_simulations, " random draws"),
       subtitle = "Binomial distribution, p=.7",  
       x= "Mean",
       y= "Frequency")+
    facet_wrap(~Sample_size, nrow = 2)
```

This is why it used to be more common to use a normal approximation to
the binomial distribution - even though the binomial distribution is
easy to compute,the z is even easier! For example, Sandidge
[@sandidge2003] noted that brown recluse spiders chose dead prey items
(as opposed to live - 2 categories!) when offered choices. This data
could be assessed using a binomial test

```{r}
 binom.test(119,(59+41+41), p=.5)
 
```

or a z-test approach by finding a z-sore

```{r}
 p=.5
 n=41+41+59
 z_score <- (119-p*n)/sqrt(n*p*(1-p))
 pnorm(z_score, lower.tail = F) *2

```

or a $\chi^2$ test, which is equivalent to a z_score but uses a squared
Z distribution (note the p-values are the same!)

```{r}
chisq.test(c(119,n-119))

```

This may seem esoteric, but understanding these issues may help you
interpret older papers while also choosing to employ more modern
statistical methods.

### QQ norm plots - commonly sed, but not needed, at this point!

In addition to considering the sample size and underlying distribution,
quantile-quantile (Q-Q) plots are sometimes used to assess normality.
These plots plot quantiles in one data set against quantiles from
another to determine if they come from similar distribution. Remember,
quantiles just order data; percentiles are example where you have 100
cut points. Q-Q norm plots consider if a given dataset are similar to a
normal distribution. If so, then the dots should match the straight line
produced by the *qqline* function.

```{r}
qqnorm(iris[iris$Species == "virginica","Sepal.Length"])
qqline(iris[iris$Species == "virginica","Sepal.Length"])
```

While we introduce Q-Q plots here, and they are often used to assess
normality, remember our tests (so far) are relying on the means of the
data being normally-distributed and not the data itself!

## What if we don't know the variance?

Assuming everything above makes sense, we are left with one issue: the
variance of the underlying population is rarely known!

In the above examples, we actually used our *estimate* of variance from
the sample to run our simulation experiment and z-test! While this works
ok for large sample sizes (yay for central limit theorem!) (and is what
statisticians relied upon historically), it doesn't work for well for
smaller sample sizes (unless we somehow know the population variance).
Our estimates for the population variance are less precise and
potentially biased at small sample sizes.

To address this issue, statisticians developed the t-distribution.
Unlike the normal distribution, its shape depends on the sample size.
This parameter is coded as degrees of freedom, commonly denoted as df,
and is equal to n - 1 (we'll come back to df later!). The major
breakthrough, however, was that df was the *only* sample-specific
parameter. The same distribution works regardless of the estimated
population variance, as a t statistic/score is created that functions
like a z score.

$$
t=\frac{\bar{x} - \mu}{\frac{s}{\sqrt{n}}} 
$$

Because it directly uses the estimate of the population variance,
smaller sample sizes show more spread (and thus make null hypotheses
more difficult to reject!). For example, note how small sample sizes
(remember, df=3 means n=4!) are notably different from the normal
distribution, while larger sample sizes become very hard to distinguish!

```{r, echo=F}
colors <- setNames( viridis(5), c("normal","df=3", "df=10", "df=20", "df=50"))
ggplot(data = data.frame(x = c(-3, 3)), aes(x)) +
  stat_function(aes(color="normal"),fun = dnorm, args = list(mean = 0, sd = 1), 
                geom = "line") + 
  stat_function(aes(color="df=3"),fun = dt, args = list( df= 3), 
                geom = "line") +
  stat_function(aes(color="df=10"),fun = dt, args = list( df= 10), 
                geom = "line") + 
  stat_function(aes(color="df=20"),fun = dt, args = list( df= 20),
                geom = "line") +
  stat_function(aes(color="df=50"),fun = dt, args = list( df= 50), 
                geom = "line") +
  labs(y="Probablity",
       x="Score (t or z)",
       color="Distribution")+
  scale_color_manual()
```

The sampling experiment is effectively what we (accidentally) carried
out earlier. To calculate the test statistic, we can also use the
*t.test* function.

```{r}
t.test(iris[iris$Species == "virginica","Sepal.Length"], mu = 7, 
             sigma.x= sd(iris[iris$Species == "virginica","Sepal.Length"]))
```

## What if we don't trust the normal approximation?
