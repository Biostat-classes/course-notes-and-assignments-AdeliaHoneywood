---
title: Estimation and probability
subtitle: Working with a sample
bibliography: references.bib
---

Now that we can describe data distributions, we want to start thinking
about how we quantify the uncertainty in our estimates (of $\mu$, for
example). Remember, we typically want to describe a population but need
to rely on a sample, and we've already talked about sampling error. So
now we just want to think about how much error we typically have (or,
alternatively, how precise are our estimates).

Answering this question is hard. Quantifying sampling error requires you
to know the "true" value for a population parameter, but we only have
estimates! Statisticians solve this problem by investigating sampling
error in populations they fully know because they created them.

For example, let's assume we measure all the males in a population.
Furthermore, let's assume the distribution of heights is *normal*.
Remember, this means the distribution is roughly symmetric, with tails
on either side. Values near the middle of the range are more common,
with the chance of getting smaller or larger values declining at an
increasing rate. In fact, in turns out \~95% of the data lies within two
standard deviations (remember those?) of the mean (so we calculate the
mean and then the standard deviation. We then subtract the standard
deviation from the mean to find a lower bound. We then addthe standard
deviation from the mean to find an upper bound. These bounds denote
where 95% of the data points will be found).
