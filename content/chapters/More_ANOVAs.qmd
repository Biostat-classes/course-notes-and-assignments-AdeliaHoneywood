---
title: More ANOVAs
subtitle: Dealing with multiple group membership and interactions
bibliography: ../references.bib
---

<!-- COMMENT NOT SHOW IN ANY OUTPUT: Code chunk below sets overall defaults for .qmd file; these inlcude showing output by default and looking for files relative to .Rpoj file, not .qmd file, which makes putting filesin different folders easier  -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

In the last chapter we introduced the idea of comparing means among
populations (one-way ANOVAs, our first linear models). However, the
units that we measure may belong to multiple groups. We will extend our
analysis of variance to consider multiple group membership and
interactions in this chapter. As a starting point, consider that group
membership may be an inherent property of the unit we measure or we may
assign it.

## Example: Back to the birds

One of the last chapters practice problems focused bird feathers. While
studying feather color in Northern flickers (*Colaptes auratus*),
@wiebe2002 noted that \~25% of birds had one or more "odd" tail
feathers. They decided to compare the color of these odd and "typical"
feathers.

[![Northern Flicker. Mike's Birds, CC BY-SA 2.0
\<https://creativecommons.org/licenses/by-sa/2.0\>, via Wikimedia
Commons](/images/Northern_Flicker_(4508135578).jpg)](https://commons.wikimedia.org/wiki/File:Northern_Flicker_(4508135578).jpg)

Example and data provided by @mcdonald2014.

```{r, echo=FALSE}
Input = ("
 Bird    Feather_type   Color_index
 A       Typical   -0.255
 B       Typical   -0.213
 C       Typical   -0.19
 D       Typical   -0.185
 E       Typical   -0.045
 F       Typical   -0.025
 G       Typical   -0.015
 H       Typical    0.003
 I       Typical    0.015
 J       Typical    0.02
 K       Typical    0.023
 L       Typical    0.04
 M       Typical    0.04
 N       Typical    0.05
 O       Typical    0.055
 P       Typical    0.058
 A       Odd       -0.324
 B       Odd       -0.185
 C       Odd       -0.299
 D       Odd       -0.144
 E       Odd       -0.027
 F       Odd       -0.039
 G       Odd       -0.264
 H       Odd       -0.077
 I       Odd       -0.017
 J       Odd       -0.169
 K       Odd       -0.096
 L       Odd       -0.33
 M       Odd       -0.346
 N       Odd       -0.191
 O       Odd       -0.128
 P       Odd       -0.182
")

feather <-  read.table(textConnection(Input),header=TRUE)
```

```{r}
library(rmarkdown)
paged_table(feather)
```

## How do we analyze this data?

We may first note that we have a continuous measurement (feather color,
measured using color hues from a digital camera and another statistical
technique that we will not go into here) and a categorical variable
(feather type, with levels "typical" and "odd"). This hopefully reminds
you of an ANOVA/t-test!

We could plot the data

```{r}
library(ggplot2)
ggplot(feather, aes(x=Feather_type, y= Color_index, color=Feather_type))+
  geom_jitter()+
  labs(y= "Color index",
       x= "Feather type",
       title="Comparing odd and typical feathers in Northern flickers")+
  guides(color=F)
```

Develop a set of hypotheses:

$$
\begin{split}
H_O: \mu_{\textrm{odd feather color}} = \mu_{\textrm{typical feather color}}\\
H_A: \mu_{\textrm{odd feather color}} \neq \mu_{\textrm{typical feather color}}\\
\end{split}
$$

and test them using a t-test:

```{r}
t.test(Color_index ~ Feather_type, data=feather)
```

or, using more generalizable functions, a linear model:

```{r}
library(car)
Anova(lm(Color_index ~ Feather_type, data=feather), type = "III")
```

We find a significant p value, **but we did not check assumptions**. For
linear models (remember, \$\epsilon \approx i.i.d.Â N(\mu,\sigma)\$, we
could use our visual checks

```{r}
plot(lm(Color_index ~ Feather_type, data=feather))
```

Which appears ok, but there is a problem.

Our data are not independent!

## Lack of Independence

Odd and typical feathers were measured on a single bird (note the *Bird*
column) in the dataset. We might assume feathers on a given bird are
more closely related in color than feathers on different birds. This
could be due to diet or other factors making all feathers on a given
bird brighter or darker than those on another. Regardless of reason (and
"good" p value), we know the measurements are linked in some way. Note
we could "connect" individual observations.

```{r}
ggplot(feather, aes(x=Feather_type, y= Color_index, color=Feather_type, group=Bird))+
  geom_line(position = position_dodge(0.4), color="black") +
  geom_point(position = position_dodge(0.4)) +  
  labs(y= "Color index",
       x= "Feather type",
       title="Comparing odd and typical feathers in Northern flickers")+
  guides(color=F)
```

When this is true, we need to consider these connections.

## Blocking, two-way ANOVAs,and paired t-tests

In this case the connections may be considered artifacts of the data. We
didn't assign birds. We also made a choice to compare odd and typical
feathers from the same bird - why? In general, accounting for extra
variation in the data will give you a better answer about how a given
variable influences outcomes. This may be called *blocking*. Although
the motivation might therefore be to get a "better" p value, it should
be driven by experimental design (and thus we started with an example
where we didn't "need" to account for it to achieve significance).

In order to consider how color differs by bird *and* feather type, we
need to add both variables to our model. This is possible because, as we
noted earlier, we can subdivide variance among multiple levels. For each
variable we add, we also add a null (and corresponding alternative)
hypothesis. So we retain our focus on feather type:

$$
\begin{split}
H_O: \mu_{\textrm{odd feather color}} = \mu_{\textrm{typical feather color}}\\
H_A: \mu_{\textrm{odd feather color}} \neq \mu_{\textrm{typical feather color}}\\
\end{split}
$$

but also add a set of hypotheses focused on birds:

$$
\begin{split}
H_O: \mu_{\textrm{color of bird A}} = \mu_{\textrm{color of bird B}}....\textrm{for all birds}\\
H_A: \mu_{\textrm{color of bird A}} \neq \mu_{\textrm{color of bird B}}....\textrm{for all birds}\\
\end{split}
$$

We can analyze this using our linear model approach. Since both
variables are categorical, this is often called a two-way ANOVA. First,
let's make the object

```{r}
two_way_anova_example <- lm(Color_index ~ Feather_type + Bird, data=feather)

```

Then check the assumptions

```{r}
plot(two_way_anova_example)
```

Note, visually speaking, the residuals do appear to be closer to normal
now. Since assumptions look ok, we can analyze the outcome

```{r}
summary(two_way_anova_example)
Anova(two_way_anova_example, type= "III")
```

Note we see a significant difference in color among birds and feather
type. Although we may be tempted to (and could) use post-hoc tests to
consider which birds are different than which others, this is typically
not done for blocked variables. We did not assign these pairings and it
is not the focus of our efforts.

Since we only had 2 types of feathers, we also don't need post-hoc
tests. A significant p value means they differ from each other, and the
estimates provided by the *summary* command indicate the typical
feathers have a higher color index.

### t-test connections

When we have only two measurements per group (e.g., odd and typical
feathers from each bird), we can use a t-test approach to achieve
similar goals. This approach is known as a paired t-test. Instead of
focusing on the difference in means (like a 2-sample t-test), the test
focuses on the mean difference between paired measurements (which would
be 0 under the null hypothesis!). In this way, it is effectively a
one-sample test that is pairing the data to reduce variation (blocking).
We can do carry out the test:

```{r}
t.test(Color_index ~ Feather_type, data=feather, paired=TRUE)
```

and get the same results as above (note we don't even have to consider
corrections like the Welch approach since this a one-sample test).
Common examples of paired t-tests include before-after and twin studies.

In an earlier chapters we considered options for one- and two-sample
tests when t-tests assumptions were not met. For two-sample tests, one
of these approaches, the sign or binary test, is only valid for paired
data. The differences in paired observations are compared to a set value
(typically 0). Under the null hypothesis, half should be below the
proposed median and half should be above. Differences matching the
proposed value are ignored, thus reducing the sample size and making it
harder to reject the null hypothesis; this is actually an odd way of
accounting for them. The proportion of values below the proposed median
is then evaluated using a binomial test. For two sample, the *SIGN.test*
function in the **BSDA** package requires 2 columns of data and assumes
the order of the column represents paired data.

```{r}
library(BSDA)
SIGN.test(feather[feather$Feather_type == "Odd", "Color_index"], 
          feather[feather$Feather_type == "Typical", "Color_index"],
          md = 0)

```

### More than 2 measurements? Back to the linear model

We can also block for variation when we take more than 2 measurements
per unit. For example, imagine if these birds also had a special, long
tail feather.

```{r}
set.seed(25)
special <- data.frame(Bird = LETTERS[1:16], Feather_type = "Special", 
                      Color_index= feather[feather$Feather_type == "Typical", "Color_index"] +
                        .3 +runif(16,1,1)*.01)
feather_extra <- merge(feather, special, all = T)
feather_extra$Feather_type <- factor(feather_extra$Feather_type)
```

We could still block for variation using the linear model/ANOVA, but not
the t-test, approach. As another review, we create the model

```{r}
more_blocks <-lm(Color_index ~ Feather_type + Bird, data=feather_extra)
```

Check assumptions

```{r}
plot(more_blocks)
```

Check outcome (this time focusing on *Anova* output)

```{r}
Anova(more_blocks, type="III")
```

We still see feather type has a significant impact on color, but since
we have more than 2 groups we need to follow up this finding with a
post-hoc test.

```{r}
library(multcomp)
compare <- glht(more_blocks, linfct = mcp(Feather_type = "Tukey"))
summary(compare)
```

## Other ways to be in multiple groups

In the bird example, one of our categories (bird) was un-intential. We
chose to measure odd and typical feathers, and accounting for variation
among birds was an appropriate step given lack of independece in
measurements. However, we can also assign units to multiple groups.
Doing so can let us consider the **main effects** of multiple variables
and potential **interactions** among them in what is often called a
**factorial ANOVA**.

For example, @valdez2023 wanted to consider the impact of top-down
(snail grazing) and bottom- up (nutrient availability) on marsh plant
(*Spartina alterniflora*) growth. To do this, they assigned plots to one
of 3 grazer treatments and one of 2 nitrogen treatments.

[![Fig 1 from Valdez et al. 2003. Map and conceptual illustration of
experimental
design.](/images/journal.pone.0286327.g001.PNG){fig-alt="Map of study site on Hog Island, Virginia, USA and conceptual illustration of experimental design with the following treatments: 1) Nitrogen addition with ambient snails, 2) nitrogen addition with three times ambient snails, 3) nitrogen addition without snails, 4) ambient nitrogen with ambient snails, 5) ambient nitrogen with three times ambient snails, and 6) ambient nitrogen without snails. The figure also depicts cage controls and uncaged plots used to assess caging effects on marsh plants. The map in the figure was created in R using ggmap [33] from Â©OpenStreetMap under a ODb license, with permission from OpenStreetMapFoundation, original copyright 2018. https://www.openstreetmap.org/copyright."}](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0286327)

This design is different from the bird example. No two measurements for
a given trait were taken on the same plot. In this case, we likely care
about the main effects, or impacts, of both variables. However, we may
also need to consider interactions among the variables. Interactions
occur when the impact of one variable depends on the level of another.
For example, snail removal might have major impacts on nitrogen-enriched
plots while having no impact on ambient plots.

Fortunately, these are easy to consider in our linear model framework.
We simply add the interaction between two variables using the ":"
notation. We'll focus on below ground biomass for this example (the
paper measured 9 response variables!)

```{r}
valdez_2023 <- read.csv("data/Spartina_alterniflora_traits.csv")
valdez_model <-lm(below.biomass..g.~Snail.Level + Nitrogen.level + Snail.Level:Nitrogen.level, valdez_2023)
```

Just like before, we first check model assumptions.

```{r}
plot(valdez_model)
```

These look ok. There may be a slight increase in variance with fitted
values, but we can work with this.

```{r, error = T}
Anova(valdez_model, type="III")
```

But we got an error! What happened? Let's look at the data

```{r}
paged_table(valdez_2023)
```

## Next steps

Our following chapters will extend ANOVAs to consider the impact of
multiple measured categories. In doing so, we will also explain paired
t-tests and sign tests for paired data. For this test, the sign of the
differences among paired observations is considered (negative or not)
and a binomial test is then used to compare the now binary data to .5
(expectation under the null hypothesis).
